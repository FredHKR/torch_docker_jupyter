
docker build -t torch_jupyter .
#testat nedanför här:


docker run --gpus all -it --rm -p 8888:8888 -v ~/torch_docker_jupyter:/torch_docker_jupyter -w ~/torch_docker_jupyter torch_jupyter

import torch
if torch.cuda.is_available():
    print("CUDA is available. Number of GPUs:", torch.cuda.device_count())
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
else:
    print("CUDA is not available.")


import torch
if torch.cuda.is_available():
    print("CUDA is available. Number of GPUs:", torch.cuda.device_count())
    for i in range(torch.cuda.device_count()):
        print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
else:
    print("CUDA is not available.")
